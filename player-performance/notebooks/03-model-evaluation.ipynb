{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2674e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec66f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1987, 324),\n",
       " good_perf\n",
       " 0    0.799698\n",
       " 1    0.200302\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/players_full_2425_with_score.csv\")\n",
    "df.shape, df[\"good_perf\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266843e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"Age\", \"90s\",\n",
    "    \"Gls_90\", \"Ast_90\", \"G+A_90\",\n",
    "    \"G-PK_90\", \"G+A-PK_90\",\n",
    "    \"xG_90\", \"xAG_90\", \"xG+xAG_90\",\n",
    "    \"npxG_90\", \"npxG+xAG_90\",\n",
    "    \"PrgC\", \"PrgP\", \"PrgR\"\n",
    "]\n",
    "\n",
    "target = \"good_perf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dab718",
   "metadata": {},
   "source": [
    "## Feature Set & Interpretation\n",
    "\n",
    "The feature set consists of **season-aggregated player statistics** (attacking, defensive, possession, discipline, and usage metrics).\n",
    "\n",
    "Because the target `good_perf` is derived from the same statistical space (via `performance_score`),\n",
    "this ML model is used for:\n",
    "\n",
    "- learning non-linear boundaries between performance tiers\n",
    "- assessing separability of player profiles\n",
    "- interpretability / feature importance analysis\n",
    "\n",
    "It is **not** used as a future match performance predictor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc2513b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna(subset=features + [target]).copy()\n",
    "\n",
    "X = df_clean[features]\n",
    "y = df_clean[target].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ae79c",
   "metadata": {},
   "source": [
    "## Target Definition (Season-Level Performance Tier)\n",
    "\n",
    "The target variable `good_perf` represents a **season-level performance tier**\n",
    "derived from the aggregated `performance_score`.\n",
    "\n",
    "- `good_perf = 1` → player belongs to the top performance tier (top 20%)\n",
    "- `good_perf = 0` → otherwise\n",
    "\n",
    "Important !!!:\n",
    "This is **not a future performance prediction task**.\n",
    "The model learns decision boundaries between **performance tiers defined by\n",
    "the scoring framework**, using season-aggregated statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a682ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.702128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>0.698795</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.868952</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.565657</td>\n",
       "      <td>0.632768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  accuracy  precision    recall        f1\n",
       "2  GradientBoosting  0.887097   0.741573  0.666667  0.702128\n",
       "0            LogReg  0.866935   0.698795  0.585859  0.637363\n",
       "1      RandomForest  0.868952   0.717949  0.565657  0.632768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "models[\"LogReg\"] = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "models[\"RandomForest\"] = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "models[\"GradientBoosting\"] = GradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_test, preds),\n",
    "        \"precision\": precision_score(y_test, preds, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, preds, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, preds, zero_division=0)\n",
    "    })\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"f1\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c277e",
   "metadata": {},
   "source": [
    "## Model Evaluation (Context)\n",
    "\n",
    "The evaluation metrics below reflect how consistently the model can separate players into **predefined season-level tiers**.\n",
    "\n",
    "High performance here indicates internal consistency of the scoring + tiering framework, not real-world forecasting ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4073515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: GradientBoosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       397\n",
      "           1       0.74      0.67      0.70        99\n",
      "\n",
      "    accuracy                           0.89       496\n",
      "   macro avg       0.83      0.80      0.82       496\n",
      "weighted avg       0.88      0.89      0.88       496\n",
      "\n",
      "Confusion matrix:\n",
      " [[374  23]\n",
      " [ 33  66]]\n"
     ]
    }
   ],
   "source": [
    "best_name = pd.DataFrame(results).sort_values(\"f1\", ascending=False).iloc[0][\"model\"]\n",
    "best_model = models[best_name]\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "print(\"Best model:\", best_name)\n",
    "print(classification_report(y_test, preds, zero_division=0))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3684ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../models/player_performance_model_B.pkl\n",
      "Saved: ../models/player_performance_features_B.json\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_model, \"../models/player_performance_model_B.pkl\")\n",
    "\n",
    "with open(\"../models/player_performance_features_B.json\", \"w\") as f:\n",
    "    json.dump(features, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", \"../models/player_performance_model_B.pkl\")\n",
    "print(\"Saved:\", \"../models/player_performance_features_B.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ac287",
   "metadata": {},
   "source": [
    "The model learns patterns associated with strong season-level performance and uses them as a proxy for upcoming match performance.\n",
    "Gradient-based ensemble models perform best, suggesting non-linear relationships between player statistics and performance labels.\n",
    "Results vary by position, reflecting the role-specific nature of football performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab2148",
   "metadata": {},
   "source": [
    "## Limitations & Future Work\n",
    "\n",
    "- Data is season-level (aggregated); no match-by-match logs are used.\n",
    "- The model does not predict future match performance.\n",
    "- The target label is derived from the same feature space (no causal inference).\n",
    "- True predictive modeling would require:\n",
    "  - match-level data\n",
    "  - temporal train/test splits\n",
    "  - external validation across seasons\n",
    "\n",
    "This will be addressed in the Match Outcome module (future extension).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "football_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
